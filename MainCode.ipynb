{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Udacity DRL Project2 - Continuous Control: PPO Solution\n",
    "#### Adapted from:\n",
    "- Shangtong Zhang: https://github.com/ShangtongZhang/DeepRL\n",
    "- Jeremi Kaczmarczyk: https://github.com/jknthn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install ./python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "\n",
    "# select this option to load version 1 (with a single agent) of the environment\n",
    "#env = UnityEnvironment(file_name='/data/Reacher_One_Linux_NoVis/Reacher_One_Linux_NoVis.x86_64')\n",
    "\n",
    "# select this option to load version 2 (with 20 agents) of the environment\n",
    "env = UnityEnvironment(file_name='/data/Reacher_Linux_NoVis/Reacher.x86_64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "from collections import namedtuple, deque\n",
    "\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "#from unityagents import UnityEnvironment\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from network_model import PPONet\n",
    "from ppo_agent import PPOAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 20\n",
      "Size of each action: 4\n",
      "There are 20 agents. Each observes a state with length: 33\n",
      "The state for the first agent looks like:\n",
      " [  0.00000000e+00  -4.00000000e+00   0.00000000e+00   1.00000000e+00\n",
      "  -0.00000000e+00  -0.00000000e+00  -4.37113883e-08   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00  -1.00000000e+01   0.00000000e+00\n",
      "   1.00000000e+00  -0.00000000e+00  -0.00000000e+00  -4.37113883e-08\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   5.75471878e+00  -1.00000000e+00\n",
      "   5.55726624e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00\n",
      "  -1.68164849e-01]\n"
     ]
    }
   ],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "\n",
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:\\n', states[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#brain.vector_action_descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#brain.vector_action_space_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config file\n",
    "config = {\n",
    "    'environment': {\n",
    "        'state_size':  env_info.vector_observations.shape[1],\n",
    "        'action_size': brain.vector_action_space_size,\n",
    "        'number_of_agents': len(env_info.agents)\n",
    "    },\n",
    "    'pytorch': {\n",
    "        'device': torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    },\n",
    "    'hyperparameters': {\n",
    "        'discount_rate': 0.99,\n",
    "        'tau': 0.95,\n",
    "        'gradient_clip': 5,\n",
    "        'rollout_length': 2048,\n",
    "        'optimization_epochs': 10,\n",
    "        'ppo_clip': 0.2,\n",
    "        'log_interval': 2048,\n",
    "        'max_steps': 1e5,\n",
    "        'mini_batch_number': 32,\n",
    "        'entropy_coefficent': 0.01,\n",
    "        'episode_count': 250,\n",
    "        'hidden_size': 512,\n",
    "        'adam_learning_rate': 3e-4,\n",
    "        'adam_epsilon': 1e-5\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xp = PPONet(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xp.forward(states) #.to.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Execute an iteration of:\n",
    "- reset env\n",
    "- fetch current state of system\n",
    "- select action \n",
    "- send action to env \n",
    "- get next state \n",
    "- get reward \n",
    "- chech if done \n",
    "- update state \n",
    "- exit if finished\n",
    "\"\"\"\n",
    "\n",
    "def step_iteration(env, brain_name, policy, config):\n",
    "    env_info = env.reset(train_mode=True)[brain_name]                       # reset the environment   \n",
    "    states = env_info.vector_observations                                   # get current state\n",
    "    scores = np.zeros(config['environment']['number_of_agents'])            # initialize scores\n",
    "    while True:                                                             # Loop until done\n",
    "        actions, _, _, _ = policy(states)                                   # select an action via the policy\n",
    "        env_info = env.step(actions.cpu().detach().numpy())[brain_name]     # send the action to the env\n",
    "        next_states = env_info.vector_observations                          # get the next state\n",
    "        rewards = env_info.rewards                                          # get the reward\n",
    "        dones = env_info.local_done                                         # see if episode has finished\n",
    "        scores += env_info.rewards                                          # update the scores with the reward\n",
    "        states = next_states                                                # update state with next_state\n",
    "        if np.any(dones):                                                   # exit loop if episode is finished\n",
    "            break\n",
    "    \n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ppo_episodes(env, brain_name, policy, config, train):\n",
    "    if train:\n",
    "        optimizier = optim.Adam(policy.parameters(), config['hyperparameters']['adam_learning_rate'], \n",
    "                        eps=config['hyperparameters']['adam_epsilon'])\n",
    "        agent = PPOAgent(env, brain_name, policy, optimizier, config)\n",
    "        all_scores = []\n",
    "        averages = []\n",
    "        last_max = 30.0\n",
    "        \n",
    "        for i in tqdm.tqdm(range(config['hyperparameters']['episode_count'])):   # do number of episodes\n",
    "            agent.step()                                                         # perform step function inside PPOAgent\n",
    "            last_mean_reward = step_iteration(env, brain_name, policy, config)   # step/loop thru an episode until \"done\"\n",
    "            last_100_average = np.mean(np.array(all_scores[-100:])) if len(all_scores) > 100 else np.mean(np.array(all_scores))\n",
    "            all_scores.append(last_mean_reward)\n",
    "            averages.append(last_100_average)\n",
    "            if last_100_average > last_max:\n",
    "                # https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
    "                # https://pytorch.org/tutorials/beginner/saving_loading_models.html#save-load-entire-model\n",
    "                # https://pytorch.org/tutorials/beginner/saving_loading_models.html#save-load-state-dict-recommended\n",
    "                #torch.save(policy.state_dict(), f\"models/ppo-max-hiddensize-{config['hyperparameters']['hidden_size']}.pth\")\n",
    "                torch.save(policy.state_dict(), f\"BestModel.pth\")\n",
    "                last_max = last_100_average\n",
    "            clear_output(True)\n",
    "            print('Episode: {} Total score this episode: {} Last {} average: {}'.format(i + 1, last_mean_reward, min(i + 1, 100), last_100_average))\n",
    "        return all_scores, averages\n",
    "    else:\n",
    "        # step/loop thru an episode until \"done\"\n",
    "        score = step_iteration(env, brain_name, policy, config)\n",
    "        return [score], [score]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --------------------------------------------------------------------------------------------- \n",
    "#### Train the PPO network with Actor-Critic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [1:27:32<00:00, 21.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 250 Total score this episode: 38.40699914153665 Last 100 average: 38.0482241495559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# TRAIN\n",
    "new_policy = PPONet(config)\n",
    "all_scores, average_scores = run_ppo_episodes(env, brain_name, new_policy, config, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ffaef5814a8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "\n",
    "ax = fig.add_subplot(221)\n",
    "plt.plot(np.arange(len(all_scores)), all_scores)\n",
    "plt.ylabel('All Scores')\n",
    "plt.xlabel('Episode #')\n",
    "\n",
    "ax = fig.add_subplot(222)\n",
    "plt.plot(np.arange(len(average_scores)), average_scores)\n",
    "plt.ylabel('Average 100 Scores')\n",
    "plt.xlabel('Episode #')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execute a run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INFER\n",
    "policy = PPONet(config)\n",
    "#policy.load_state_dict(torch.load('models/ppo-max-hiddensize-512.pth'))\n",
    "policy.load_state_dict(torch.load('BestModel.pth'))\n",
    "_, _ = run_ppo_episodes(env, brain_name, policy, config, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizier = optim.Adam(policy.parameters(), config['hyperparameters']['adam_learning_rate'], \n",
    "#                        eps=config['hyperparameters']['adam_epsilon'])\n",
    "#agent = PPOAgent(env, brain_name, policy, optimizier, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#play_round(env, brain_name, policy, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions, _, _, _ = policy(states)\n",
    "print(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy.forward(states)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
